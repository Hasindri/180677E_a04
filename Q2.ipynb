{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train:  (50000, 32, 32, 3)\ny_train:  (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print('x_train: ', x_train.shape)\n",
    "print('y_train: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Noof classes: 10\nNoof training images: 50000\nNoof test images: 10000\nNoof features: 3072\n"
     ]
    }
   ],
   "source": [
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "print('Noof classes:',K)\n",
    "print('Noof training images:',Ntr)\n",
    "print('Noof test images:',Nte)\n",
    "print('Noof features:',Din)\n",
    "\n",
    "x_train=x_train[range(Ntr),:]\n",
    "y_train=y_train[range(Ntr),:]\n",
    "x_test=x_test[range(Nte),:]\n",
    "x_test=x_test[range(Nte),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "original labels: (50000, 1)\nlabels in class matrix: (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('original labels:',y_train.shape)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "print('labels in class matrix:',y_train.shape)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train: (50000, 3072)\nx_test: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train,(Ntr,Din))\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "print('x_train:', x_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize pixel values\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image"
   ]
  },
  {
   "source": [
    "##### <html><h><font color='purple'>Two Layer Fully Connected Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "w1: (3072, 200)\nb1: (200,)\nw2: (200, 10)\nb2: (10,)\n"
     ]
    }
   ],
   "source": [
    "H=200\n",
    "std=1e-6\n",
    "w1 = std*np.random.randn(Din, H)\n",
    "w2 = std*np.random.randn(H, K)\n",
    "b1 = np.zeros(H)\n",
    "b2=np.zeros(K)\n",
    "print(\"w1:\", w1.shape)\n",
    "print(\"b1:\", b1.shape)\n",
    "print(\"w2:\", w2.shape)\n",
    "print(\"b2:\", b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0/300: train loss= 0.999998-- ,test loss= 0.999998--,train accuracy= 0.729182--, test accuracy= 0.730000\n",
      "epoch 10/300: train loss= 1.001895-- ,test loss= 1.002002--,train accuracy= 0.561732--, test accuracy= 0.556260\n",
      "epoch 20/300: train loss= 0.857652-- ,test loss= 0.856458--,train accuracy= 0.723238--, test accuracy= 0.721060\n",
      "epoch 30/300: train loss= 0.835320-- ,test loss= 0.835577--,train accuracy= 0.734228--, test accuracy= 0.734690\n",
      "epoch 40/300: train loss= 0.826136-- ,test loss= 0.826840--,train accuracy= 0.744198--, test accuracy= 0.742110\n",
      "epoch 50/300: train loss= 0.815369-- ,test loss= 0.815933--,train accuracy= 0.751262--, test accuracy= 0.753560\n",
      "epoch 60/300: train loss= 0.806431-- ,test loss= 0.808048--,train accuracy= 0.756498--, test accuracy= 0.759870\n",
      "epoch 70/300: train loss= 0.799359-- ,test loss= 0.801689--,train accuracy= 0.761762--, test accuracy= 0.764840\n",
      "epoch 80/300: train loss= 0.799471-- ,test loss= 0.801394--,train accuracy= 0.759086--, test accuracy= 0.758200\n",
      "epoch 90/300: train loss= 0.797461-- ,test loss= 0.800022--,train accuracy= 0.764126--, test accuracy= 0.764580\n",
      "epoch 100/300: train loss= 0.799675-- ,test loss= 0.802750--,train accuracy= 0.761248--, test accuracy= 0.760720\n",
      "epoch 110/300: train loss= 0.789446-- ,test loss= 0.793129--,train accuracy= 0.771396--, test accuracy= 0.771280\n",
      "epoch 120/300: train loss= 0.778012-- ,test loss= 0.781923--,train accuracy= 0.775828--, test accuracy= 0.772770\n",
      "epoch 130/300: train loss= 0.773786-- ,test loss= 0.780377--,train accuracy= 0.777150--, test accuracy= 0.772610\n",
      "epoch 140/300: train loss= 0.771730-- ,test loss= 0.777374--,train accuracy= 0.781838--, test accuracy= 0.782630\n",
      "epoch 150/300: train loss= 0.769544-- ,test loss= 0.776269--,train accuracy= 0.781250--, test accuracy= 0.781670\n",
      "epoch 160/300: train loss= 0.774784-- ,test loss= 0.782957--,train accuracy= 0.777788--, test accuracy= 0.774410\n",
      "epoch 170/300: train loss= 0.757216-- ,test loss= 0.767068--,train accuracy= 0.791764--, test accuracy= 0.788230\n",
      "epoch 180/300: train loss= 0.767354-- ,test loss= 0.777665--,train accuracy= 0.783906--, test accuracy= 0.776300\n",
      "epoch 190/300: train loss= 0.752819-- ,test loss= 0.765802--,train accuracy= 0.790680--, test accuracy= 0.785750\n",
      "epoch 200/300: train loss= 0.748600-- ,test loss= 0.762348--,train accuracy= 0.794990--, test accuracy= 0.790330\n",
      "epoch 210/300: train loss= 0.751363-- ,test loss= 0.765073--,train accuracy= 0.794016--, test accuracy= 0.788040\n",
      "epoch 220/300: train loss= 0.750685-- ,test loss= 0.767207--,train accuracy= 0.793080--, test accuracy= 0.781710\n",
      "epoch 230/300: train loss= 0.751401-- ,test loss= 0.767752--,train accuracy= 0.786042--, test accuracy= 0.782440\n",
      "epoch 240/300: train loss= 0.747712-- ,test loss= 0.764249--,train accuracy= 0.798140--, test accuracy= 0.784460\n",
      "epoch 250/300: train loss= 0.745980-- ,test loss= 0.764425--,train accuracy= 0.800786--, test accuracy= 0.783850\n",
      "epoch 260/300: train loss= 0.743687-- ,test loss= 0.761637--,train accuracy= 0.795928--, test accuracy= 0.783450\n",
      "epoch 270/300: train loss= 0.740459-- ,test loss= 0.758128--,train accuracy= 0.798238--, test accuracy= 0.787560\n",
      "epoch 280/300: train loss= 0.748302-- ,test loss= 0.767314--,train accuracy= 0.796982--, test accuracy= 0.780840\n",
      "epoch 290/300: train loss= 0.745698-- ,test loss= 0.766620--,train accuracy= 0.790612--, test accuracy= 0.780260\n"
     ]
    }
   ],
   "source": [
    "batch_size = Ntr\n",
    "iterations = 300\n",
    "lr = 1.4e-2\n",
    "lr_decay=0.999\n",
    "reg =5e-6\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "seed = 0\n",
    "#rng = np.random.default_rng(seed=seed)\n",
    "for t in range(iterations):\n",
    "    indices = np.random.choice(Ntr,batch_size)\n",
    "    #rng.shuffle(indices)\n",
    "    x=x_train[indices]\n",
    "    y=y_train[indices]\n",
    "\n",
    "    # Forward pass\n",
    "    z1=1.0/(1.0 + np.exp(-(x.dot(w1)+b1)))\n",
    "    y_pred=z1.dot(w2)+b2\n",
    "    z=1.0/(1.0 + np.exp(-(x_test.dot(w1)+b1)))\n",
    "    y_pred_test=z.dot(w2)+b2\n",
    "\n",
    "    #loss\n",
    "    loss=(1.0/batch_size)*np.square(y_pred-y).sum() + reg * (np.sum(w1*w1) + np.sum(w2*w2))\n",
    "    test_loss=(1.0/Nte)*np.square(y_pred_test-y_test).sum() + reg * (np.sum(w1*w1) + np.sum(w2*w2))\n",
    "    train_loss_history.append(loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "\n",
    "    #accuracy\n",
    "    train_acc = 1.0 - (1/(batch_size*K))*(np.abs(np.argmax(y,axis=1) - np.argmax(y_pred,axis=1))).sum()\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_acc = 1.0 - (1/(Nte*K))*(np.abs(np.argmax(y_test,axis=1) - np.argmax(y_pred_test,axis=1))).sum()\n",
    "    test_acc_history.append(test_acc)\n",
    "\n",
    "    if t%10==0:\n",
    "        print('epoch %d/%d: train loss= %f-- ,test loss= %f--,train accuracy= %f--, test accuracy= %f' % (t,iterations,loss,test_loss,train_acc,test_acc))\n",
    "\n",
    "        \n",
    "    # Backward pass\n",
    "\n",
    "    dy_pred=(1./batch_size)*2.0*(y_pred-y)\n",
    "    dw2=z1.T.dot(dy_pred) + reg * w2\n",
    "    db2=dy_pred.sum(axis=0)\n",
    "    dz1=dy_pred.dot(w2.T)\n",
    "    dw1=x.T.dot(dz1*z1*(1-z1))+reg*w1\n",
    "    db1=(dz1*z1*(1-z1)).sum(axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    w1 -= lr*dw1\n",
    "    w2 -= lr*dw2\n",
    "    b1 -= lr*db1\n",
    "    b2 -= lr*db2\n",
    "    lr *= lr_decay\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}
{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "df54c64f53f67be694600507bfad15457e67369e3bc8a48c7b33116abed0e094"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Noof classes: 10\nNoof training images: 50000\nNoof test images: 10000\nNoof features: 3072\n"
     ]
    }
   ],
   "source": [
    "K = len(np.unique(y_train)) # Classes\n",
    "Ntr = x_train.shape[0]\n",
    "Nte = x_test.shape[0]\n",
    "Din = 3072 # CIFAR10\n",
    "print('Noof classes:',K)\n",
    "print('Noof training images:',Ntr)\n",
    "print('Noof test images:',Nte)\n",
    "print('Noof features:',Din)\n",
    "\n",
    "x_train=x_train[range(Ntr),:]\n",
    "y_train=y_train[range(Ntr),:]\n",
    "x_test=x_test[range(Nte),:]\n",
    "x_test=x_test[range(Nte),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "original labels: (50000, 1)\n",
      "labels in class matrix: (50000, 10)\n",
      "x_train: (50000, 3072)\n",
      "x_test: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "print('original labels:',y_train.shape)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=K)\n",
    "print('labels in class matrix:',y_train.shape)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=K)\n",
    "\n",
    "x_train = np.reshape(x_train,(Ntr,Din))\n",
    "x_test = np.reshape(x_test,(Nte,Din))\n",
    "print('x_train:', x_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize pixel values\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train = x_train - mean_image\n",
    "x_test = x_test - mean_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "w1: (3072, 200)\nb1: (200,)\nw2: (200, 10)\nb2: (10,)\n"
     ]
    }
   ],
   "source": [
    "H=200\n",
    "std=1e-6\n",
    "w1 = std*np.random.randn(Din, H)\n",
    "w2 = std*np.random.randn(H, K)\n",
    "b1 = np.zeros(H)\n",
    "b2=np.zeros(K)\n",
    "print(\"w1:\", w1.shape)\n",
    "print(\"b1:\", b1.shape)\n",
    "print(\"w2:\", w2.shape)\n",
    "print(\"b2:\", b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 0/300: train loss= 0.747635-- ,test loss= 0.771751--,train accuracy= 0.795200--, test accuracy= 0.780480\n",
      "epoch 10/300: train loss= 0.782559-- ,test loss= 0.779988--,train accuracy= 0.770400--, test accuracy= 0.774110\n",
      "epoch 20/300: train loss= 0.773794-- ,test loss= 0.775199--,train accuracy= 0.770600--, test accuracy= 0.782600\n",
      "epoch 30/300: train loss= 0.779001-- ,test loss= 0.775631--,train accuracy= 0.792600--, test accuracy= 0.784080\n",
      "epoch 40/300: train loss= 0.783227-- ,test loss= 0.775139--,train accuracy= 0.779200--, test accuracy= 0.788540\n",
      "epoch 50/300: train loss= 0.751493-- ,test loss= 0.767492--,train accuracy= 0.801200--, test accuracy= 0.782460\n",
      "epoch 60/300: train loss= 0.763654-- ,test loss= 0.771161--,train accuracy= 0.762200--, test accuracy= 0.780100\n",
      "epoch 70/300: train loss= 0.765465-- ,test loss= 0.772608--,train accuracy= 0.788000--, test accuracy= 0.781350\n",
      "epoch 80/300: train loss= 0.764949-- ,test loss= 0.772618--,train accuracy= 0.775400--, test accuracy= 0.777780\n",
      "epoch 90/300: train loss= 0.765781-- ,test loss= 0.775972--,train accuracy= 0.766800--, test accuracy= 0.773680\n",
      "epoch 100/300: train loss= 0.739031-- ,test loss= 0.768255--,train accuracy= 0.799400--, test accuracy= 0.782850\n",
      "epoch 110/300: train loss= 0.776545-- ,test loss= 0.774678--,train accuracy= 0.783200--, test accuracy= 0.775660\n",
      "epoch 120/300: train loss= 0.755447-- ,test loss= 0.765866--,train accuracy= 0.792400--, test accuracy= 0.785080\n",
      "epoch 130/300: train loss= 0.766554-- ,test loss= 0.766412--,train accuracy= 0.795600--, test accuracy= 0.788830\n",
      "epoch 140/300: train loss= 0.768722-- ,test loss= 0.767870--,train accuracy= 0.775000--, test accuracy= 0.789700\n",
      "epoch 150/300: train loss= 0.743189-- ,test loss= 0.761773--,train accuracy= 0.804000--, test accuracy= 0.786110\n",
      "epoch 160/300: train loss= 0.750277-- ,test loss= 0.763867--,train accuracy= 0.784200--, test accuracy= 0.783710\n",
      "epoch 170/300: train loss= 0.755134-- ,test loss= 0.763793--,train accuracy= 0.789200--, test accuracy= 0.788440\n",
      "epoch 180/300: train loss= 0.754116-- ,test loss= 0.762556--,train accuracy= 0.780800--, test accuracy= 0.785220\n",
      "epoch 190/300: train loss= 0.754684-- ,test loss= 0.767964--,train accuracy= 0.772400--, test accuracy= 0.780720\n",
      "epoch 200/300: train loss= 0.727202-- ,test loss= 0.761151--,train accuracy= 0.803400--, test accuracy= 0.786480\n",
      "epoch 210/300: train loss= 0.764079-- ,test loss= 0.764380--,train accuracy= 0.781800--, test accuracy= 0.785950\n",
      "epoch 220/300: train loss= 0.745755-- ,test loss= 0.762998--,train accuracy= 0.795800--, test accuracy= 0.787890\n",
      "epoch 230/300: train loss= 0.759412-- ,test loss= 0.763613--,train accuracy= 0.795800--, test accuracy= 0.787900\n",
      "epoch 240/300: train loss= 0.752214-- ,test loss= 0.758083--,train accuracy= 0.795000--, test accuracy= 0.793880\n",
      "epoch 250/300: train loss= 0.730079-- ,test loss= 0.757043--,train accuracy= 0.823200--, test accuracy= 0.791830\n",
      "epoch 260/300: train loss= 0.741482-- ,test loss= 0.758161--,train accuracy= 0.784000--, test accuracy= 0.788280\n",
      "epoch 270/300: train loss= 0.744892-- ,test loss= 0.760921--,train accuracy= 0.794400--, test accuracy= 0.788540\n",
      "epoch 280/300: train loss= 0.742871-- ,test loss= 0.759450--,train accuracy= 0.774800--, test accuracy= 0.787610\n",
      "epoch 290/300: train loss= 0.742591-- ,test loss= 0.764060--,train accuracy= 0.780600--, test accuracy= 0.784450\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "step=Ntr/batch_size\n",
    "iterations = 300\n",
    "lr = 1.4e-2\n",
    "lr_decay=0.999\n",
    "reg =5e-6\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "test_loss_history = []\n",
    "test_acc_history = []\n",
    "seed = 0\n",
    "\n",
    "for t in range(iterations):\n",
    "    start=int(batch_size*((t)%step))\n",
    "\n",
    "    x=x_train[start:start+batch_size,:]\n",
    "    y=y_train[start:start+batch_size,:]\n",
    "\n",
    "    # Forward pass\n",
    "    z1=1.0/(1.0 + np.exp(-(x.dot(w1)+b1)))\n",
    "    y_pred=z1.dot(w2)+b2\n",
    "    z=1.0/(1.0 + np.exp(-(x_test.dot(w1)+b1)))\n",
    "    y_pred_test=z.dot(w2)+b2\n",
    "\n",
    "    #loss\n",
    "    loss=(1.0/batch_size)*np.square(y_pred-y).sum() + reg * (np.sum(w1*w1) + np.sum(w2*w2))\n",
    "    test_loss=(1.0/Nte)*np.square(y_pred_test-y_test).sum() + reg * (np.sum(w1*w1) + np.sum(w2*w2))\n",
    "    train_loss_history.append(loss)\n",
    "    test_loss_history.append(test_loss)\n",
    "\n",
    "    #accuracy\n",
    "    train_acc = 1.0 - (1/(batch_size*K))*(np.abs(np.argmax(y,axis=1) - np.argmax(y_pred,axis=1))).sum()\n",
    "    train_acc_history.append(train_acc)\n",
    "    test_acc = 1.0 - (1/(Nte*K))*(np.abs(np.argmax(y_test,axis=1) - np.argmax(y_pred_test,axis=1))).sum()\n",
    "    test_acc_history.append(test_acc)\n",
    "\n",
    "    if t%10==0:\n",
    "        print('epoch %d/%d: train loss= %f-- ,test loss= %f--,train accuracy= %f--, test accuracy= %f' % (t,iterations,loss,test_loss,train_acc,test_acc))\n",
    "\n",
    "        \n",
    "    # Backward pass\n",
    "\n",
    "    dy_pred=(1./batch_size)*2.0*(y_pred-y)\n",
    "    dw2=z1.T.dot(dy_pred) + reg * w2\n",
    "    db2=dy_pred.sum(axis=0)\n",
    "    dz1=dy_pred.dot(w2.T)\n",
    "    dw1=x.T.dot(dz1*z1*(1-z1))+reg*w1\n",
    "    db1=(dz1*z1*(1-z1)).sum(axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    w1 -= lr*dw1\n",
    "    w2 -= lr*dw2\n",
    "    b1 -= lr*db1\n",
    "    b2 -= lr*db2\n",
    "    lr *= lr_decay\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}